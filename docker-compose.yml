version: '3.8'

services:
  attallah-assistant:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: attallah-assistant
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_TELEMETRY_DISABLED=1
      # Ollama configuration (uncomment if using Ollama)
      # - OLLAMA_BASE_URL=http://ollama:11434
      # - OLLAMA_MODEL=llama2
    volumes:
      # For persistent logs
      - ./logs:/app/logs
      # For environment files
      - ./.env.local:/app/.env.local:ro
    depends_on:
      - redis
    networks:
      - attallah-network
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        compress: "true"

  # Optional: Redis for caching and session management
  redis:
    image: redis:7-alpine
    container_name: attallah-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./redis.conf:/etc/redis/redis.conf:ro
    command: redis-server /etc/redis/redis.conf
    networks:
      - attallah-network
    # Resource limits for Redis
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.2'
        reservations:
          memory: 128M
          cpus: '0.1'
    # Health check
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Optional: Ollama service (uncomment if using local Ollama)
  # ollama:
  #   image: ollama/ollama
  #   container_name: attallah-ollama
  #   restart: unless-stopped
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   networks:
  #     - attallah-network
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 4G
  #         cpus: '2.0'
  #       reservations:
  #         memory: 2G
  #         cpus: '1.0'

  # Optional: Nginx reverse proxy for production
  nginx:
    image: nginx:alpine
    container_name: attallah-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - attallah-assistant
    networks:
      - attallah-network
    # Resource limits for Nginx
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.1'
        reservations:
          memory: 64M
          cpus: '0.05'

volumes:
  redis_data:
    driver: local
  # ollama_data:
  #   driver: local

networks:
  attallah-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16